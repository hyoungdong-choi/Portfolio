# DevOps/Infra Engineer Portfolio

안녕하세요! 대규모 인프라와 DevOps 업무에 관심이 많은 엔지니어입니다.  
아래는 전기차 충전기 서비스 인프라 구축 시 진행했던 여러 프로젝트입니다.

---

## 프로젝트 A: Rancher 기반 Kubernetes 환경 운영

### 개요
- **목적**: 사내에서 이미 구축된 MSA(마이크로서비스) 아키텍처를 효율적으로 운영하고, Rancher를 통해 클러스터 상태와 리소스를 직관적으로 관리  
- **기간**: 202X.XX ~ 202X.XX  
- **주요 기술**:  
  - **Rancher**, **Kubernetes**, **Docker**  

### 수행 내용
1. **클러스터 운영**  
   - Rancher UI로 멀티 클러스터와 노드 상태를 실시간 파악  
   - Helm 차트를 사용해 배포 파이프라인 자동화  
2. **운영상 개선 사항 적용**  
   - 워크로드 리소스 최적화(메모리·CPU 리밋 조정, 스케일링 정책 검토)  
   - RBAC 역할 재정비로 보안과 편의성 모두 충족

### 성과 / 어려움 극복
- **성과**:  
  - 쿠버네티스 운영 효율 상승 → 장애 대응 시간 단축, 서비스 안정성 향상  
  - Rancher 도입 후 운영팀과 개발팀 간 협업 지표 개선(한눈에 클러스터 상태 공유)  
- **어려움 & 해결**:  
  - 기존 MSA 구조가 복잡해 리소스 배포 시 충돌 → Helm 차트에 의존 관계 명시 및 테스트 환경 구축  
  - Rancher RBAC 구성 시 혼선 → 표준 정책 마련 후 일괄 적용

---

## 프로젝트 B: Proxmox·Ansible 기반 테스트 환경 구축

### 개요
- **목적**: 사내 개발/테스트 서버 환경을 효율적으로 운영하고, 초기 설정을 자동화  
- **기간**: 202X.XX ~ 202X.XX  
- **주요 기술**: 
  - **Proxmox** (가상화/컨테이너 플랫폼)  
  - **Ansible** (IaC, 자동화)

### 수행 내용
1. **Proxmox로 VM 관리**  
   - Dev/QA 환경에서 VM 생성·삭제, 스냅샷을 신속하게 관리  
   - 테스트 실패 시 스냅샷 복구로 재실행 시간 단축
2. **Ansible 플레이북 작성**  
   - 서버 초깃값, 패키지 설치, 사용자 권한, 방화벽 규칙 등을 자동화  
   - 운영 환경과 동일한 설정을 테스트 환경에도 적용해 재현성 강화

### 성과 / 어려움 극복
- **성과**:  
  - 테스트 환경 셋업 시간 약 50% 단축  
  - 환경별 설정 불일치 문제 감소(운영-테스트 차이 최소화)
- **어려움 & 해결**:  
  - Proxmox 환경 내 네트워킹 이슈 → Ansible 플레이북에서 표준 네트워크 구성을 강제  
  - 팀원 간 플레이북 작성 스타일 상이 → Ansible 역할(Role)로 템플릿 표준화

---

## 프로젝트 C: DB 샤딩 (MongoDB·Vitess) 도입

### 개요
- **목적**: 데이터 폭증에 대비해 쓰기·읽기 부하 분산 처리 및 스케일아웃 지원  
- **기간**: 202X.XX ~ 202X.XX  
- **주요 기술**: 
  - **MongoDB Sharding**  
  - **Vitess** (MySQL Sharding 솔루션)

### 수행 내용
1. **MongoDB Sharding 운영**  
   - 고속 쓰기가 필요한 로그/충전 이력 테이블을 MongoDB로 전환  
   - 샤딩 키 설계 및 Chunk Balancer 튜닝
2. **Vitess 기반 MySQL 샤딩**  
   - 사용자/결제/정산 등 관계형 데이터 처리  
   - 무중단 샤딩 구조로 확장성과 가용성 확보

### 성과 / 어려움 극복
- **성과**:  
  - 트래픽 급증에도 DB 응답 속도 안정 유지  
  - 서버 증설 시 무중단 확장 가능
- **어려움 & 해결**:  
  - Shard 키 설정 부적절 시 성능 저하 → 실제 트래픽 패턴 분석 후 최적 분산 구조 설계  
  - MySQL→Vitess 전환 중 데이터 불일치 → 주기적 동기화와 체크섬으로 해결

---

## 프로젝트 D: IDC 서버 교체 및 NHN 클라우드 이전

### 개요
- **목적**: 노후 IDC 서버를 교체해 물리적 안정성을 확보하고, 이후 NHN 클라우드로 전환  
- **기간**: 202X.XX ~ 202X.XX  
- **주요 기술**: 
  - **서버 하드웨어 교체**(IDC 실서버 리프레시)  
  - **NHN Cloud** (클라우드 인프라)  
  - **Terraform/Ansible** (인프라 자동화)

### 수행 내용
1. **IDC 서버 교체(하드웨어 리프레시)**  
   - 노후 서버 성능 저하 및 부품 단종 문제 발생  
   - 신형 서버로 교체 후 안정화 테스트(네트워크 트래픽, Disk I/O 등)
2. **NHN 클라우드로 마이그레이션**  
   - Terraform으로 VPC·서브넷·보안 그룹 자동 정의  
   - Blue-Green/Rolling Update로 무중단 이전 진행

### 성과 / 어려움 극복
- **성과**:  
  - IDC 서버 교체로 하드웨어 장애률 감소  
  - NHN 클라우드 전환으로 스케일링 자동화·비용 절감
- **어려움 & 해결**:  
  - IDC-클라우드 간 네트워크 VPN 차이 → 사전 테스트 환경 구성으로 문제점 미리 발굴  
  - 리소스 비용 예측 → 모니터링 강화를 통해 최적화 적용

---

## 프로젝트 E: 모니터링/로그 시스템 고도화

### 개요
- **목적**: 서비스 상태 추적 및 장애 원인 파악을 위한 고도화된 모니터링·로그 체계 마련  
- **기간**: 202X.XX ~ 202X.XX  
- **주요 기술**: 
  - **Telegraf**, **VictoriaMetrics**, **Grafana**, **Alertmanager**  
  - **promtail**, **victorialogs**

### 수행 내용
1. **지표 수집 & 시계열 DB**  
   - Telegraf로 서버/컨테이너 지표 수집  
   - VictoriaMetrics에 대규모 시계열 데이터 저장
2. **시각화·알림**  
   - Grafana로 대시보드 구성, Alertmanager로 임계값 초과 시 Slack/Email 알림  
   - 트렌드 분석 및 실시간 대응 강화
3. **로그 수집**  
   - promtail이 컨테이너 로그를 victorialogs로 전송  
   - 로그와 지표를 연계해 장애 시점을 빠르게 추적

### 성과 / 어려움 극복
- **성과**:  
  - 장애 탐지 시간 40% 이상 단축  
  - 운영팀·개발팀 간 협업 효과 상승(공동 대시보드 사용)
- **어려움 & 해결**:  
  - 로그·메트릭 연계 미흡 → 공통 ID, 레이블링으로 단일 인터페이스 제공  
  - 알람 노이즈 → Alertmanager 룰 세분화 및 이중 기준 적용

---

## 프로젝트 F: Velero + Minio 백업/복구

### 개요
- **목적**: 쿠버네티스 애플리케이션 및 데이터 백업, 재해 복구 시나리오 확립  
- **기간**: 202X.XX ~ 202X.XX  
- **주요 기술**: 
  - **Velero**, **Minio**(S3 호환 스토리지)

### 수행 내용
1. **백업 아키텍처**  
   - Velero로 쿠버네티스 리소스·퍼시스턴트 볼륨(PV)을 주기적으로 백업  
   - Minio를 S3 호환 대상으로 구성해 백업 데이터를 보관
2. **복구 절차 테스트**  
   - 단일 파드 장애, 노드 장애 등 시나리오별 복구 절차 수립  
   - 실제 클러스터에서 반복 테스트해 신뢰도 확보

### 성과 / 어려움 극복
- **성과**:  
  - 백업/복구 자동화로 재해 발생 시 신속 복원 가능  
  - 운영 편의성과 안정성 동시 확보
- **어려움 & 해결**:  
  - 대용량 볼륨 백업 중 부하 이슈 → 비업무 시간대 백업 스케줄링, QoS 조정  
  - 증분 관리 → Velero 플러그인 및 Minio 버전 관리 기능을 활용해 효율적 운영

---

## 🛠️ 운영 기술 (운영만 담당)

- **NATS (메시지 브로커)**  
  - 이미 구축된 MSA 환경 내 실시간 메시지 브로커로 활용  
  - 운영 과정에서 메시지 라우팅 설정·성능 모니터링·트러블슈팅  
- **Harbor (컨테이너 레지스트리)**  
  - 이미 구축된 레지스트리에 대해 이미지 업로드·보안 스캔·정책 관리  
  - CI/CD 파이프라인 자동화와 연계하여 배포 안정성 향상  

---

## 🛠️ 기술 스택 요약

- **Container Orchestration**: Rancher, Kubernetes, Docker  
- **Databases**: MongoDB Sharding, Vitess(MySQL Sharding)  
- **Cloud/Virtualization**: NHN Cloud, Proxmox  
- **IaC & CI/CD**: Ansible, Terraform, Jenkins  
- **Monitoring/Logging**: Telegraf, VictoriaMetrics, Grafana, Alertmanager, promtail, victorialogs  
- **Backup/Restore**: Velero + Minio  
- **(운영)** MSA, NATS, Harbor  

---

## 🏆 요약 및 소감

이처럼 여러 프로젝트를 진행하면서 **쿠버네티스 운영**, **DB 샤딩**, **IDC 서버 교체**, **클라우드 마이그레이션**, **모니터링·로그 고도화**, **백업·복구 자동화** 등 인프라 전반을 경험할 수 있었습니다. 이미 구축된 **MSA 아키텍처** 환경에서는 **NATS** 메시지 브로커와 **Harbor** 컨테이너 레지스트리를 운영함으로써, 대규모 서비스에서의 메시지 흐름과 이미지 관리의 중요성을 체감했습니다.

향후에도 변화하는 기술 트렌드를 적극 학습하고 적용하여, **확장성과 안정성을 갖춘 인프라**를 제공하는 엔지니어로 성장하겠습니다. 감사합니다!
